[["index.html", "02 Buenas Prácticas Capítulo 1 Análisis 16s rRNA utilizando DADA2", " 02 Buenas Prácticas . 2024-03-04 Capítulo 1 Análisis 16s rRNA utilizando DADA2 .rmdnote { padding: 10px; margin-bottom: 15px; border: 1px solid #abcdef; background-color: #f3f3f3; border-radius: 5px; } "],["introducción-a-dada2.html", "Capítulo 2 Introducción a DADA2 2.1 Instalación de DADA2 en R (versión 4.3) 2.2 Configuramos el directorio en el que se ubican las reads 2.3 Ordenamos los archivos y extraemos el nombre de las muestras 2.4 Establecer ruta para archivos filtrados 2.5 Filtrar y recortar lecturas 2.6 Estimación de la tasa de error 2.7 Dereplicar lecturas 2.8 Inferencia de secuencias 2.9 Fusionar lecturas emparejadas 2.10 Crear tabla de secuencias 2.11 Eliminar quimeras 2.12 Asignar taxonomía 2.13 Impresión de resultados 2.14 Alinear secuencias 2.15 Crear matriz de distancia 2.16 Realizar Neighbor Joining 2.17 Actualizamos el modelo con nuevos parámetros 2.18 Optimizamos el modelo GTR con parámetros de inversión y tasa de gamma 2.19 Desacoplamos el paquete phangorn para evitar conflictos 2.20 Leemos los metadatos de las muestras desde un archivo CSV 2.21 Verificamos que los nombres de las filas de la tabla de secuencias coincidan con los metadatos 2.22 Construimos un objeto phyloseq con la tabla de OTU, los metadatos de las muestras, la tabla taxonómica y el árbol filogenético 2.23 Eliminamos las muestras sintéticas del objeto phyloseq 2.24 Imprimimos el objeto phyloseq resultante", " Capítulo 2 Introducción a DADA2 Repositorio de GitHub aquí Cita: Callahan, B. J., McMurdie, P. J., Rosen, M. J., Han, A. W., Johnson, A. J. A., y Holmes, S. P. (2016). DADA2: High-resolution sample inference from Illumina amplicon data. Nature methods, 13(7), 581-583. Descripción: DADA2 es un paquete de software de código abierto utilizado para modelar y corregir errores en secuencias de amplicones secuenciados con el protocolo Illumina. Infiere secuencias de una muestra de manera exacta y resuelve diferencias con una resolución de un nucleótido. Los datos utilizados pueden ser consultados en el European Nucleotide Archive (ENA) bajo el nombre de proyecto PRJNA428495. Descargamos los archivos FASTQ en la sección “Generated FASTQ files: FTP” y los guardamos en una carpeta. Los binarios del paquete DADA2 están disponibles a través de Bioconductor 2.1 Instalación de DADA2 en R (versión 4.3) Este bloque instala el paquete DADA2 a través de Bioconductor. Es importante tener instalado BiocManager para poder acceder a los paquetes de Bioconductor. if (!require(&quot;BiocManager&quot;, quietly = TRUE)) install.packages(&quot;BiocManager&quot;) BiocManager::install(&quot;dada2&quot;) library(dada2) 2.2 Configuramos el directorio en el que se ubican las reads path &lt;- &quot;/Users/&quot; # Cambiamos al directorio que contiene las reads list.files(path) 2.3 Ordenamos los archivos y extraemos el nombre de las muestras Este bloque ordena los archivos FASTQ y extrae el nombre de las muestras. Asegúrate de que los patrones de búsqueda (pattern=“_1.fastq.gz” y pattern=“_2.fastq.gz”) coincidan con la nomenclatura de tus archivos. fnFs &lt;- sort(list.files(path, pattern=&quot;_1.fastq.gz&quot;)) fnRs &lt;- sort(list.files(path, pattern=&quot;_2.fastq.gz&quot;)) sample.names &lt;- sapply(strsplit(fnFs, &quot;_&quot;), &#39;[&#39;, 1) fnFs &lt;- file.path(path, fnFs) fnRs &lt;- file.path(path, fnRs) 2.4 Establecer ruta para archivos filtrados Define una ruta basada en la variable sample.names donde guardar los archivos filtrados. El código genera nombres de archivo con un sufijo (“_F_filt.fastq.gz” o “_R_filt.fastq.gz”) para diferenciarlos. filt_path &lt;- file.path(path, &quot;filtered&quot;) filtFs &lt;- file.path(filt_path, paste0(sample.names, &quot;_F_filt.fastq.gz&quot;)) filtRs &lt;- file.path(filt_path, paste0(sample.names, &quot;_R_filt.fastq.gz&quot;)) print(fnFs) print(fnRs) print(filtFs) print(filtRs) 2.5 Filtrar y recortar lecturas La función filterAndTrim se utiliza para el filtrado y recorte de las lecturas, es decir, se eliminan las lecturas de baja calidad y las recorta a una longitud específica. Se especifican varios parámetros, como las longitudes de truncamiento, la calidad máxima permitida, la eliminación de secuencias de fagos (rm.phix), la compresión y el uso de múltiples hilos (multithread). El resultado se almacena en la variable out. Windows 10 permite el ‘multi-theading’, excepto en el comando filterAndTrim. out &lt;- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(250, 200), maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE, compress=TRUE, multithread=TRUE) 2.6 Estimación de la tasa de error Se estima la tasa de error para las lecturas adelante (errF) y las lecturas reversas (errR) utilizando la función learnErrors. La opción multithread=TRUE se utiliza para acelerar el proceso. errF &lt;- learnErrors(filtFs, multithread=TRUE) errR &lt;- learnErrors(filtRs, multithread=TRUE) 2.7 Dereplicar lecturas Se realiza la eliminación de duplicados de lecturas (dereplicación) para las lecturas adelante (derepFs) y las lecturas reversas (derepRs) utilizando la función derepFastq. Se asignan nombres a las muestras con sample.names. derepFs &lt;- derepFastq(filtFs, verbose=TRUE) derepRs &lt;- derepFastq(filtRs, verbose=TRUE) names(derepFs) &lt;- sample.names names(derepRs) &lt;- sample.names 2.8 Inferencia de secuencias Se utilizan las tasas de error estimadas en el paso anterior para la inferencia de secuencias únicas utilizando la función dada para las lecturas adelante (dadaFs) y las lecturas reversas (dadaRs). dadaRs &lt;- dada(derepRs, err=errR, multithread=TRUE) dadaFs &lt;- dada(derepFs, err=errF, multithread=TRUE) 2.9 Fusionar lecturas emparejadas Aquí se fusiona las secuencias emparejadas utilizando la función mergePairs. Las secuencias únicas y las lecturas originales se utilizan para la fusión, y los resultados se almacenan en la variable mergers. mergers &lt;- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE) 2.10 Crear tabla de secuencias Se crea una tabla de secuencias utilizando la función makeSequenceTable. Esta tabla contendrá información sobre las secuencias y su abundancia. seqtab &lt;- makeSequenceTable(mergers) 2.11 Eliminar quimeras Las quimeras son secuencias que resultan de la combinación de dos o más secuencias parentales diferentes durante el proceso de amplificación por PCR. Estas formaciones ocurren en ciclos posteriores de PCR cuando hay una alta concentración de cebadores parcialmente extendidos que compiten con los cebadores originales. Se realiza la eliminación de quimeras utilizando la función removeBimeraDenovo. Se especifica el método de eliminación como “consensus”. seqtab.nochim &lt;- removeBimeraDenovo(seqtab, method=&quot;consensus&quot;, multithread=TRUE, verbose=TRUE) Las quimeras puede introducir artefactos¿¿‘¿’¿ en los análisis de datos, dando lugar a interpretaciones erróneas. En el análisis de datos usando DADA2, las quimeras se eliminan utilizando el código removeBimeraDenovo. Esta función es una interfaz de conveniencia para la eliminación de quimeras. DADA2 ofrece varios métodos para identificar quimeras, como la identificación a partir de secuencias agrupadas y la identificación por consenso entre muestras. Al utilizar el método de consenso, por ejemplo, las muestras en una tabla de secuencias se verifican independientemente en busca de quimeras, y se toma una decisión de consenso sobre cada variante de secuencia. DADA2 es muy meticuloso al tratar con estas quimeras para asegurar que los datos analizados sean precisos. Por ejemplo, al utilizar removeBimeraDenovo con el método “pooled”, todas las muestras en la tabla de secuencias se agrupan para la identificación de quimeras. Si se usa el método “consensus”, las muestras en una tabla de secuencias se verifican independientemente en busca de quimeras, y se toma una decisión de consenso sobre cada variante de secuencia. Esto es vital ya que las quimeras pueden variar entre las muestras y es esencial asegurarse de que no afecten los resultados. En conclusión, eliminar quimeras o bimeras es esencial para obtener una representación precisa de las comunidades microbianas en los análisis de datos. Si no se eliminan, podrían llevar a interpretaciones erróneas de la estructura y diversidad de la comunidad. DADA2 proporciona herramientas efectivas para identificar y eliminar estas quimeras, asegurando así la calidad y precisión de los resultados obtenidos. 2.12 Asignar taxonomía Se asigna la taxonomía a las secuencias utilizando la función assignTaxonomy. Se proporciona un archivo de referencia para la asignación taxonómica, y se utiliza el multithread para acelerar el proceso. La base de datos taxonómica utilizada será un archivo fasta de entrenamiento derivado de la versión 138.1 del Proyecto Silva y formateado para su uso con DADA2. Este archivo puede ser descargado de Zenodo. taxa &lt;- assignTaxonomy(seqtab.nochim, &quot;C:/Users/UBBBC/Desktop/Samuel/PRJNA428495/silva_nr99_v138.1_train_set.fa.gz&quot;, multithread=TRUE) 2.13 Impresión de resultados Se imprime en la consola las primeras filas de la asignación taxonómica resultante. unname(head(taxa)) 2.14 Alinear secuencias ‘getSequences’ extrae las secuencias de la tabla sin quimeras. ‘names(sequences)’ asigna a cada secuencia su propio nombre para su fácil identificación. sequences &lt;- getSequences(seqtab.nochim) names(sequences) &lt;- sequences ‘AlignSeqs’ de la biblioteca ‘DECIPHER’ alinea las secuencias de ADN. ‘DNAStringSet’ convierte las secuencias en un formato adecuado para el alineamiento. ‘anchor=NA’ indica que no se usará un anclaje durante el alineamiento. alignment &lt;- AlignSeqs(DNAStringSet(sequences), anchor=NA) 2.15 Crear matriz de distancia ‘phyDat’ convierte las alineaciones en un formato que puede ser utilizado por funciones de filogenética. ‘type=“DNA”’ especifica que los datos son secuencias de ADN. ‘dist.ml’ calcula una matriz de distancias utilizando el método de máxima verosimilitud. phang.align &lt;- phyDat(as(alignment, &quot;matrix&quot;), type=&quot;DNA&quot;) dm &lt;- dist.ml(phang.align) 2.16 Realizar Neighbor Joining ‘NJ’ realiza un análisis filogenético utilizando el método Neighbor Joining. La salida es un árbol filogenético basado en la matriz de distancias. treeNJ &lt;- NJ(dm) # NJ es Neighbor Joining fit &lt;- pml(treeNJ, data=phang.align) ‘pml’ (de la biblioteca phangorn) ajusta un modelo de máxima verosimilitud al árbol filogenético. ‘treeNJ’ es el árbol generado por Neighbor Joining. ‘data=phang.align’ son los datos de alineación convertidos previamente con ‘phyDat’. 2.17 Actualizamos el modelo con nuevos parámetros fitGTR &lt;- update(fit, k=4, inv=0.2) update: Actualiza un modelo previamente ajustado (fit) con nuevos parámetros. k=4: Define el número de categorías de tasa para el modelo gamma de tasas de sustitución de nucleótidos variables entre sitios. inv=0.2: Establece la proporción de sitios invariables en 0.2. “JUSTIFICACIÓN” 2.18 Optimizamos el modelo GTR con parámetros de inversión y tasa de gamma fitGTR &lt;- optim.pml(fitGTR, model=&quot;GTR&quot;, optInv=TRUE, optGamma=TRUE, rearrangement = &quot;stochastic&quot;, control = pml.control(trace = 0)) optim.pml1 2.19 Desacoplamos el paquete phangorn para evitar conflictos detach(&quot;package:phangorn&quot;, unload=TRUE) 2.20 Leemos los metadatos de las muestras desde un archivo CSV samdf &lt;- read.csv(&quot;metadata.csv&quot;, header=TRUE, row.names = 1) 2.21 Verificamos que los nombres de las filas de la tabla de secuencias coincidan con los metadatos rownames(seqtabNoC) %in% rownames(samdf) all(rownames(seqtabAll) %in% samdf$run) 2.22 Construimos un objeto phyloseq con la tabla de OTU, los metadatos de las muestras, la tabla taxonómica y el árbol filogenético ps &lt;- phyloseq(otu_table(seqtabNoC, taxa_are_rows=FALSE), sample_data(samdf), tax_table(taxTab), phy_tree(fitGTR$tree)) Phyloseq . 2.23 Eliminamos las muestras sintéticas del objeto phyloseq ps &lt;- prune_samples(sample_names(ps) != &quot;Mock&quot;, ps) 2.24 Imprimimos el objeto phyloseq resultante ps Optimiza un modelo filogenético basado en máxima verosimilitud.↩︎ "],["buenas-prácticas.html", "Capítulo 3 Buenas Prácticas 3.1 Estrategias de análsis 3.2 Cross-references 3.3 Chapters and sub-chapters 3.4 Captioned figures and tables", " Capítulo 3 Buenas Prácticas 3.1 Estrategias de análsis 3.1.1 Comparación de “pipelines” Al comparar pipelines para el análisis de datos de secuenciación del gen 16S rRNA, se deben considerar factores como la facilidad de uso, la documentación disponible y el tiempo de análisis. Pipelines populares como QIIME, MG-RAST, UPARSE y mothur ofrecen herramientas completas desde el control de calidad hasta el agrupamiento OTUs. Sin embargo, la accesibilidad para usuarios con conocimientos computacionales limitados y la calidad de la documentación varían entre estos paquetes. Estudios han mostrado que aunque herramientas como mothur y QIIME tienen documentación extensa que puede ser ventajosa, el tiempo de análisis y la facilidad de uso difieren significativamente entre los paquetes, con QIIME siendo rápido (aproximadamente 1 hora) y MG-RAST más lento (aproximadamente 2 días) pero adecuado para usuarios sin experiencia en línea de comandos. La elección del pipeline dependerá del nivel de experiencia del usuario y de los recursos disponibles en su institución. 3.2 Cross-references Cross-references make it easier for your readers to find and link to elements in your book. 3.3 Chapters and sub-chapters There are two steps to cross-reference any heading: Label the heading: # Hello world {#nice-label}. Leave the label off if you like the automated heading generated based on your heading title: for example, # Hello world = # Hello world {#hello-world}. To label an un-numbered heading, use: # Hello world {-#nice-label} or {# Hello world .unnumbered}. Next, reference the labeled heading anywhere in the text using \\@ref(nice-label); for example, please see Chapter 3.2. If you prefer text as the link instead of a numbered reference use: any text you want can go here. 3.4 Captioned figures and tables Figures and tables with captions can also be cross-referenced from elsewhere in your book using \\@ref(fig:chunk-label) and \\@ref(tab:chunk-label), respectively. See Figure 3.1. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 3.1: Here is a nice figure! Don’t miss Table 3.1. knitr::kable( head(pressure, 10), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 3.1: Here is a nice table! temperature pressure 0 0.0002 20 0.0012 40 0.0060 60 0.0300 80 0.0900 100 0.2700 120 0.7500 140 1.8500 160 4.2000 180 8.8000 La geocomputación ha evolucionado significativamente en las últimas décadas "]]
